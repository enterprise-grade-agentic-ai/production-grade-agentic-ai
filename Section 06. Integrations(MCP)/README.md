# üîó Section 06. Integrations (MCP)

## üéØ Purpose
This sections focuses on Integrations using MCP. Demos in the course included making `Tavily web search` tools and `publish to S3` tool available to the agents. These tools were made available through MCP Gateway. This repo contains the code used for the demos.

## üõ†Ô∏è Installation
This project uses [UV](https://docs.astral.sh/uv/) for dependency management and package handling, offering a seamless setup and execution experience.

First, if you haven't already, install uv:
```bash
pip install uv
```

Next, navigate to your project directory and install the dependencies:
```bash
uv sync
```

## ‚úÖ Pre-requisites
___Instead of automating the pre-requisites, most of the steps are kept as manual. This has been intentionally done so that the learner can grasp the concepts in more detail.___

### AWS CLI Setup
___If not already done in the previous sections___, you may follow below steps to setup AWS CLI:
1. Install AWS CLI using [User Guide](https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html)
2. Configure AWS CLI using the below command on the terminal. Try to keep region as `us-east-1` as it generally gets the latest updates. 
```bash
aws configure 
```
Note: The AWS key or user used in `aws configure` command should have read and write permissions for AWS Bedrock, AgentCore Runtime, AgentCore Memory, AgentCore MCP, AWS Cognito, and AWS Secrets Manager.

### Env file setup
___If not already done in the previous sections___, you may copy `.env.template` as `.env` and populate it as mentioned in the subsequent steps.

### AWS Secrets Manager Setup (Optional)
We are talking about production grade agentic AI. Which means we shouldn't have secrets sprinkled in the local environment file or code. To ensure this security best practice, ideally you should create a secret in AWS secrets manager of type `Other type of secret`. You can populate secrets like `OpenAI key`, `Langfuse private key` in this container secret as key value pair. Key is the secret name, and value is the secret value. You needn't populate secrets in it as of now. AWS might stop you from saving the secret without any key value. You may save a dummy key value just to proceed.

After that set below variables in the `.env` file present in the current folder:
```python
SECRET_NAME=<Name of the secret as created in the AWS Secrets Manager>
SECRET_REGION=<AWS region where this secret is created, e.g. us-east-1>
```
The code is already in place to load the secrets from this container into environment file. Please note that secrets stored in AWS secrets manager costs. If you wouldn't like to incur that cost, you may set secrets in the local `.env` file. In that case, for security reasons, you should only try out the agentic application on local machine only.

### OpenAI Setup (Only if using OpenAI models)
:memo: This repo by default uses Amazon's Nova Pro model. But in my personal experience, OpenAI's gpt models perform better. You may consider setting up OpenAI for this repo if your budget allows.

___If not already done in the previous sections___, and you would like to use OpenAI models, you may follow below steps.
1. Generate OpenAI key if you would like to use OpenAI models. This can be done on [OpenAI Platform](https://platform.openai.com/). Please note that using OpenAI models would require minimum payment of $5 to OpenAI.
2. Set below key in the AWS secret containing secrets. This would be automatically loaded in the environment variables of the application. If you are not using AWS secret and just trying on you local, you may set this in `.env` file. 
```python
OPENAI_API_KEY=<Key as generated by OpenAI>
```

### Langfuse Setup (For observability)
___If not already done in the previous sections___, you may setup Langfuse for observability using the below steps:
1. Generate Langfuse keys on Langfuse.
2. Set below keys in the AWS secret containing secrets. This would be automatically loaded in the environment variables of the application. If you are not using AWS secret and just trying on local, you may set these in `.env` file. 
```
LANGFUSE_PUBLIC_KEY=<Public key as generated by Langfuse>
LANGFUSE_SECRET_KEY=<Secret key as generated by Langfuse>
LANGFUSE_BASE_URL=<Host as specified by Langfuse while generating the keys>
```

### AWS Cognito Setup
___If not already done in the previous sections___, you may setup cognito for authentication for MCP Gateway.

1. To setup AWS Cognito, you may run:
```bash
sh miscellaneous/cognitoSetup.sh 
```
Please note down Discovery URL as printed on the terminal.

### üÜï Setup Tavily for agents searching internet
___This is a new pre-requisite introduced in this section___. You may setup Tavily as per the steps below:
1. Create [Tavily](https://www.tavily.com/) account for agents to search web. Create an API key in Tavily and copy it to clipboard. 
2. Visit AWS AgentCore Console and go to the identity section, and add an API key with the following details:
```
Name: TavilyAPIKey
API key: <Tavily API Key created in previous step>
```

### üÜï AWS Lambda function for publishing the report to AWS S3
___This is a new pre-requisite introduced in this section___. You may setup Lambda function as per the steps below:
1. Create a S3 bucket which will contain the generated reports
2. Create a AWS Lambda function which will be used to publish the reports to S3
 * Function Type: `Author from scratch`
 * Function Name: `publishReportToS3`
 * Runtime: `Python 3.14` or above
 * Function Code: Copy the code from a file in this repo - `miscellaneous/publishToS3Function.py`
 * Function environment variables
   * `S3_BUCKET_NAME` = `<Name of the bucket as created earlier>`
3. With all the above changes, you may deploy the Lambda function
4. Go to `Function -> Configuration -> Permissions` and open the details of Execution Role in AWS IAM. In the execution role, you may edit the policy and add below statement to allow writing to the S3 bucket created above.
```json
{
  "Sid": "WriteToS3",
  "Effect": "Allow",
  "Action": [
    "s3:PutObject"
  ],
  "Resource": [
    "<S3_BUCKET_NAME>/*"
  ]
}
```

### üÜï AWS AgentCore MCP Gateway Setup
___This is a new pre-requisite introduced in this section___. You may setup MCP Gateway as per the steps below:

1. To setup Client ID for MCP Gateway, you may go to `AWS Cognito Console -> User Pool Created in previous steps -> App Clients` and create an App Client of type `Machine-to-machine application`. You may note down `Client ID` and `Client Secret` of the newly created client ID for MCP Gateway. Store these values in the below environment variables or as key values in the AWS Secret.
```python
MCP_CLIENT_ID=<Client ID of the app client created for MCP Gateway>
MCP_CLIENT_SECRET=<Client Secret of the app client created for MCP Gateway>
```

2. Visit Cognito Discovery URL in a web browser, and pick up `token_endpoint` from the the JSON returned from the Discovery URL. Store below environment variable.
```python
MCP_TOKEN_URL=<token_endpoint as seen in the Discovery URL>
```

3. Create a MCP Gateway in AgentCore console using below configurations:
* Inbound Auth Type: `JWT`
* JWT schema configuration: `Use existing Identity provider configurations` . 
* Use Discovery URL as received from AWS Cognito
* Client value of `MCP_CLIENT_ID`

4. Copy the `Gateway resource URL` of the newly created MCP Gateway and set below environment variable in the `.env` file
```python
MCP_GATEWAY_URL=<Gateway resource URL>
```
5. Create two targets in the newly created MCP Gateway:
  * __Target for Tavily__
    * Target Name: Tavily-Target
    * Target Type: Integrations
    * Integration Provider: Tavily
    * API Key: `<Key created in previous step>`
  * __Target for Publishing Reports to S3__
    * Target Name: PublishTools
    * Target Type: Lambda ARN
    * Lambda ARN: `ARN of Lambda function created earlier`
    * Target Schema (Inline Schema): Schema available at `miscellaneous/publishToS3Schema.json`
    * Outbound Auth: IAM

## üöÄ Running the Project
:memo: It is a good idea to observe every execution trace in Langfuse. If LLM call isn't visible in the trace, try seeing the output of the agents in agent spans. It should have response returned from LLMs. 

### Explore MCP Gateway using MCP Inspector
First let us explore MCP Gateway directly using MCP Inspector. You may refer to the below steps:
1. Generate a bearer token to connect to the MCP Gateway by using the below command on terminal. Do remember to replace values for variables beginning with `MCP_`
```bash
curl -X POST <MCP_TOKEN_URL> -H "Content-Type: application/x-www-form-urlencoded" -d "grant_type=client_credentials&client_id=<MCP_CLIENT_ID>&client_secret=<MCP_CLIENT_SECRET>"
```
This command will return a JSON. You may copy the value of `access_token`. This will be used in subsequent steps to connect to the MCP Gateway.

2. Launch MCP Inspector using the below command on terminal:
```bash
npx @modelcontextprotocol/inspector
```
3. Connect to the MCP Gateway in the MCP Inspector, using below connection attributes:
  * Transport Type: Streamable HTTP
  * URL: `<MCP_GATEWAY_URL>`
  * Connection Type: Direct
  * Authentication:
    * Custom Header
      * Header Name: `Authorization`
      * Header Value: `Bearer <access_token>`
4. Once the connection is successful, you may explore `List Tools` feature and even invoking `Tavily` tools and `Publish to S3` tool. Before proceeding to the next steps, please ensure that all tools are successfully executing.

### Emerging Technology Research using tools exposed by MCP Gateway
After playing around with MCP Inspector, now is the time to execute its integration with our emerging technology research agentic application. You may follow below steps to execute it.
1. Run the CLI interface using the below command:
```bash
uv run python -m src.emergingtechnologyresearch.run
```
2. CLI will ask you for the research topic. You may enter emerging technology of your choice. The execution will take around a minute. If it is successful, it will return the S3 object URL. You may explore the S3 object in AWS S3 console. And explore the JSON created by this agentic application.
3. Do remember to explore the execution trace in Langfuse. This will give you fair idea on how are tools picked and executed.


**Happy Learning! üéâü§ñ**